# Sanford

## Recommendations

Machine Learning and Artificial Intelligence applications have unique computing demands.

No "one size fits all" approach to specification and investment exists.

This curated collection of articles stands to influence your specification and investment decision criteria.

* [What's Driving the Hype Cycle for Generative AI, 2024](https://www.gartner.com/en/articles/hype-cycle-for-genai)
* [AI vs. Generative AI: The Differences Explained](https://www.coursera.org/articles/ai-vs-generative-ai)
* [Choosing Your Path in Generative AI: Open-Source or Proprietary?](https://attri.ai/blog/choosing-your-path-in-generative-ai-open-source-or-proprietary)
* [Facing GPU Shortages and Rising Cloud Costs in the Era of GenAI](https://generativeai.pub/facing-gpu-shortages-and-rising-cloud-costs-in-the-era-of-genai-7908420a8d79)
* [Hardware Recommendations for Machine Learning and Artificial Intelligence](https://www.pugetsystems.com/solutions/ai-and-hpc-workstations/machine-learning-ai/hardware-recommendations)
* [CPU vs GPU for Machine Learning](https://blog.purestorage.com/purely-educational/cpu-vs-gpu-for-machine-learning)
* [Why do I need a GPU for ML/AI](https://www.reddit.com/r/learnmachinelearning/comments/184so8i/why_do_i_need_a_gpu_for_mlai)
* [Do we need GPUs/NPUs for local AI?](https://medium.com/@andreask_75652/do-we-need-gpus-npus-for-local-ai-b6cd9b60f00c)
* [Buying a PC for Local AI? These are the specs taht actually matter](https://www.theregister.com/2024/08/25/ai_pc_buying_guide/)
* [How to run LLMs with less GPU and CPU memory](https://medium.com/data-science-in-your-pocket/how-to-run-llms-in-less-gpu-and-cpu-memory-6989e6ec5621)
* [The Hidden Bottleneck: How GPU Memory Hierarchy Affects Your Computing Experience](https://www.digitalocean.com/community/tutorials/the-hidden-bottleneck-how-gpu-memory-hierarchy-affects-your-computing-experience)
* [AI and Memory Wall](https://arxiv.org/abs/2403.14123)
* [Generative AI on the Edge: Architecture and Performance Evaluation](https://arxiv.org/html/2411.17712v1)
* [LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators](https://arxiv.org/pdf/2411.00136)