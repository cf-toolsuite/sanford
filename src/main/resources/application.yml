spring:
  application:
    name: sanford

  httpclient5:
    pool:
      default-connection-config:
        socket-timeout: PT10M

  mvc:
    async:
      request-timeout: ${SPRING_MVC_ASYNC_REQUEST_TIMEOUT:-1}

  threads:
    virtual:
      enabled: true

  docker:
    compose:
      enabled: false

  servlet:
    multipart:
      max-file-size: 100MB
      max-request-size: 100MB

management:
  info:
    build:
      enabled: true
    git:
      mode: FULL
    java:
      enabled: true
    os:
      enabled: true
  endpoint:
    health:
      show-details: ALWAYS
    metrics:
      enabled: true
    prometheus:
      enabled: true
    env:
      enabled: true
      show-values: ALWAYS
    configprops:
      enabled: true
      show-values: ALWAYS
  endpoints:
    web:
      exposure:
        include: info,health,metrics,scheduledtasks,loggers,prometheus,sbom
  tracing:
    sampling:
      probability: 1.0

server:
  tomcat:
    max-swallow-size: -1

app:
  supportedContentTypes:
    md: text/markdown
    pdf: application/pdf
    log: text/plain
    txt: text/plain
    csv: text/csv
    tsv: text/tab-separated-values
    json: application/json
    xml: application/xml
    html: text/html
    htm: text/html
    doc: application/msword
    docx: application/vnd.openxmlformats-officedocument.wordprocessingml.document
    ppt: application/vnd.ms-powerpoint
    pptx: application/vnd.openxmlformats-officedocument.presentationml.presentation

springdoc:
  api-docs:
    enabled: true
    path: /api-docs
  packagesToScan: org.cftoolsuite.controller
  show-actuator: true
  swagger-ui:
    enabled: true
    path: /swagger-ui.html
  writer-with-default-pretty-printer: true

---

spring:
  config:
    activate:
      on-profile: alting
    import: "${SPRING_CONFIG_IMPORT:optional:file:./config/creds.yml}"

  ai:
    alting:
      chat:
        options:
          models:
            - anthracite-org/magnum-v4-72b
            - anthropic/claude-3.5-sonnet-20240620:beta
            - google/gemini-pro-1.5
            - gryphe/mythomax-l2-13b
            - mistralai/mixtral-8x7b-instruct
            - neversleep/llama-3.1-lumimaid-70b
            - nousresearch/hermes-3-llama-3.1-405b
            - openai/gpt-4o-mini
            - perplexity/llama-3.1-sonar-huge-128k-online
            - pygmalionai/mythalion-13b
            - qwen/qwen-2.5-7b-instruct
            - x-ai/grok-beta

    openai:
      base_url: ${OPENAI_BASE_URL:https://alting.ai/api}
      chat:
        options:
          model: ${CHAT_MODEL:google/gemini-pro-1.5}
      embedding:
        base_url: ${EMBEDDING_BASEURL:https://api.openai.com}
        options:
          model: ${EMBEDDING_MODEL:text-embedding-3-large}

---

spring:
  config:
    activate:
      on-profile: arize-phoenix

arize:
  phoenix:
    base_url: ${ARIZE_PHOENIX_BASE_URL:http://localhost:6006}/v1

management:
  otlp:
    metrics:
      export:
        url: ${arize.phoenix.base_url}/metrics
        step: 10s
    tracing:
      endpoint: ${arize.phoenix.base_url}/traces

---

spring:
  config:
    activate:
      on-profile: bedrock

  autoconfigure:
    exclude: org.springframework.ai.autoconfigure.openai.OpenAiAutoConfiguration

  ai:
    bedrock:
      aws:
        access-key: ${AWS_ACCESS_KEY_ID}
        secret-key: ${AWS_SECRET_ACCESS_KEY}
        session-token: ${AWS_SESSION_TOKEN:}
        region: ${AWS_REGION:us-west-2}
      converse:
        chat:
          enabled: ${BEDROCK_CONVERSE_CHAT_ENABLED:true}
          options:
            model: ${CHAT_MODEL:amazon.nova-lite-v1:0}
      llama:
        chat:
          enabled: ${BEDROCK_LLAMA_CHAT_ENABLED:false}
          model: ${CHAT_MODEL:meta.llama3-70b-instruct-v1:0}
      anthropic3:
        chat:
          enabled: ${BEDROCK_ANTHROPIC3_CHAT_ENABLED:false}
          model: ${CHAT_MODEL:anthropic.claude-3-sonnet-20240229-v1:0}
      cohere:
        chat:
          enabled: ${BEDROCK_COHERE_CHAT_ENABLED:false}
          model: ${CHAT_MODEL:cohere.command-text-v14}
        embedding:
          enabled: ${BEDROCK_COHERE_EMBEDDING_ENABLED:true}
          model: ${EMBEDDING_MODEL:cohere.embed-english-v3}
      jurassic2:
        chat:
          enabled: ${BEDROCK_JURASSIC2_CHAT_ENABLED:false}
          model: ${CHAT_MODEL:ai21.j2-ultra-v1}
      titan:
        chat:
          enabled: ${BEDROCK_TITAN_CHAT_ENABLED:false}
          model: ${CHAT_MODEL:amazon.titan-text-lite-v1}
        embedding:
          enabled: ${BEDROCK_TITAN_EMBEDDING_ENABLED:false}
          model: ${EMBEDDING_MODEL:amazon.titan-embed-image-v1}

---

spring:
  config:
    activate:
      on-profile: gemini

  autoconfigure:
    exclude: org.springframework.ai.autoconfigure.openai.OpenAiAutoConfiguration

  ai:
    vertex:
      ai:
        gemini:
          projectId: ${PROJECT_ID}
          location: ${REGION:us-west1}
          chat:
            options:
              model: ${CHAT_MODEL:gemini-1.5-flash-002}
              googleSearchRetrieval: true
        embedding:
          projectId: ${PROJECT_ID}
          location: ${REGION:us-west1}
          text:
            options:
              model: ${EMBEDDING_MODEL:text-embedding-005}

---

spring:
  config:
    activate:
      on-profile: groq-cloud
    import: "${SPRING_CONFIG_IMPORT:optional:file:./config/creds.yml}"

  ai:
    openai:
      base_url: ${OPENAI_BASE_URL:https://api.groq.com/openai}
      chat:
        options:
          model: ${CHAT_MODEL:llama-3.3-70b-versatile}
      embedding:
        base_url: ${EMBEDDING_BASEURL:https://api.openai.com}
        options:
          model: ${EMBEDDING_MODEL:text-embedding-3-large}

---

spring:
  config:
    activate:
      on-profile: openai
    import: "${SPRING_CONFIG_IMPORT:optional:file:./config/creds.yml}"

  ai:
    openai:
      audio:
        speech:
          options:
            # Supported formats are: mp3, opus, aac, flac, wav, and pcm
            response-format: mp3
            # Available options are: alloy, echo, fable, onyx, nova, and shimmer
            voice: nova
            # The speed of the voice synthesis. The acceptable range is from 0.25 (slowest) to 4.0 (fastest).
            speed: 1.0f
        transcription:
          options:
            prompt: "Transcribe the audio"
            # @see https://docs.oracle.com/javase/8/docs/api/java/util/Locale.html#getISOLanguages--
            language: en
            # The format of the transcript output, in one of these options: json, text, srt, verbose_json, or vtt
            response-format: vtt
      chat:
        options:
          model: ${CHAT_MODEL:gpt-4o-mini}
      embedding:
        options:
          model: ${EMBEDDING_MODEL:text-embedding-3-large}

---

spring:
  config:
    activate:
      on-profile: ollama

  autoconfigure:
    exclude: org.springframework.ai.autoconfigure.openai.OpenAiAutoConfiguration

  ai:
    ollama:
      base-url: ${OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: ${CHAT_MODEL:mistral}
          num-ctx: ${CHAT_MODEL_CONTEXT_LENGTH:32768}
          truncate: false
      embedding:
        options:
          model: ${EMBEDDING_MODEL:nomic-embed-text}

---

spring:
  config:
    activate:
      on-profile: docker

  docker:
    compose:
      enabled: true
      lifecycle-management: start-and-stop
      stop:
        command: down
        arguments: -v
      timeout: 1m

---

spring:
  config:
    activate:
      on-profile: chroma

  ai:
    vectorstore:
      chroma:
        initialize-schema: true

  docker:
    compose:
      file:
        - ./docker/docker-compose.chroma.yml
        - ./docker/docker-compose.${storage.provider}.yml

---

spring:
  config:
    activate:
      on-profile: gemfire

  ai:
    vectorstore:
      gemfire:
        buckets: 1
        indexName: spring-ai-gemfire-index
        host: ${GEMFIRE_HOST:localhost}
        port: ${GEMFIRE_PORT:7071}
        initialize-schema: true
        vector-similarity-function: COSINE

  docker:
    compose:
      file:
        - ./docker/docker-compose.gemfire.yml
        - ./docker/docker-compose.${storage.provider}.yml

---

spring:
  config:
    activate:
      on-profile: pgvector

  datasource:
    driver-class-name: ${SPRING_DATASOURCE_DRIVER_CLASS_NAME:org.postgresql.Driver}
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/pgvector}
    username: ${SPRING_DATASOURCE_USER:postgres}
    password: ${SPRING_DATASOURCE_PASSWORD:postgres}

  ai:
    vectorstore:
      pgvector:
        initialize-schema: true
        index-type: HNSW
        distance-type: COSINE_DISTANCE
        dimensions: ${SPRING_AI_VECTORSTORE_PGVECTOR_DIMENSIONS:768}

  docker:
    compose:
      file:
        - ./docker/docker-compose.pgvector.yml
        - ./docker/docker-compose.${storage.provider}.yml

---

spring:
  config:
    activate:
      on-profile: redis

  ai:
    vectorstore:
      redis:
        uri: ${SPRING_REDIS_URI:redis://localhost:6379}
        initialize-schema: true

  docker:
    compose:
      file:
        - ./docker/docker-compose.redis.yml
        - ./docker/docker-compose.${storage.provider}.yml

---

spring:
  config:
    activate:
      on-profile: weaviate

  ai:
    vectorstore:
      weaviate:
        host: ${WEAVIATE_HOST:localhost:8088}
        scheme: ${WEAVIATE_SCHEME:http}
        initialize-schema: true

  docker:
    compose:
      file:
        - ./docker/docker-compose.weaviate.yml
        - ./docker/docker-compose.${storage.provider}.yml

---

spring:
  config:
    activate:
      on-profile: minio

minio:
  endpoint:
    host: ${MINIO_ENDPOINT_HOST:localhost}
    port: ${MINIO_ENDPOINT_PORT:9000}
    scheme: ${MINIO_ENDPOINT_SCHEME:http}
  accessKey: ${MINIO_ACCESS_KEY:minio}
  secretKey: ${MINIO_SECRET_KEY:g0dmini0}
  bucket:
    name: ${MINIO_BUCKET_NAME:sanford}

---

spring:
  config:
    activate:
      on-profile: dev

  ai:
    ollama:
      init:
        pull-model-strategy: always
        timeout: 15m
        max-retries: 3
        keep_alive: 15m
    vectorstore:
      pgvector:
        remove-existing-vector-store-table: true

debug: true

management:
  endpoints:
    web:
      exposure:
        include: "*"

logging:
  level:
    org.cftoolsuite: TRACE
    software.amazon.awssdk: DEBUG
    org.springframework.ai: DEBUG
    com.fasterxml.jackson: TRACE
